{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Data for SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head=()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Display options to ensure feature name visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning Suppression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many rows have missing ID ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['customer_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop ID Feature from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['customer_id'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Target and Independent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[['churn']]\n",
    "X=df.drop(['churn'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Response Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split features into Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=X.select_dtypes(include=\"number\")\n",
    "char=X.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num.describe(percentiles=[0.01,0.05,0.10,0.25,0.50,0.75,0.85,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capping and Flooring of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_cap(x):\n",
    "    x=x.clip(lower=x.quantile(0.01))\n",
    "    x=x.clip(upper=x.quantile(0.99))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=num.apply(lambda x : outlier_cap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num.describe(percentiles=[0.01,0.05,0.10,0.25,0.50,0.75,0.85,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Handling - Numerical Features (Remove >25% Missing Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=num.loc[:,num.isnull().mean()<=0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Handling - Numerical Features (Imputation with Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "num_1=pd.DataFrame(imputer.fit_transform(num),index=num.index,columns=num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Handling - Categorical Features (Remove >25% Missing Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char=char.loc[:,char.isnull().mean()<=0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Handling - Categorical Features (Imputation with Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "char_1=pd.DataFrame(imputer.fit_transform(char),index=char.index,columns=char.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_1.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features with n-1 levels\n",
    "X_char_dum = pd.get_dummies(char_1, drop_first = True)\n",
    "X_char_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Master Feature Set for Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all=pd.concat([X_char_dum,num_1],axis=1,join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale the data to be between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std=pd.DataFrame(scaler.fit_transform(X_all),index=X_all.index,columns=X_all.columns).add_suffix('_std')\n",
    "X_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_std, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of Training Data\",X_train.shape)\n",
    "print(\"Shape of Testing Data\",X_test.shape)\n",
    "print(\"Response Rate in Training Data\",y_train.mean())\n",
    "print(\"Response Rate in Testing Data\",y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm= SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    " 'C': (np.arange(0.1,1,0.1)) , 'kernel': ['linear'],\n",
    " 'C': (np.arange(0.1,1,0.1)) , 'gamma': [0.01,0.02,0.03,0.04,0.05], 'kernel': ['rbf'],\n",
    " 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05], 'C':(np.arange(0.1,1,0.1)) , 'kernel':['poly']\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm_model = GridSearchCV(svm, param_dist,cv=10,scoring='accuracy',n_jobs=3)\n",
    "svm_model.fit(X_train,y_train)\n",
    "print('Best Parameters using grid search: \\n', svm_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred_xgb=xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_xgb))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_xgb))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(xgb,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = xgb.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_xgb']=pd.qcut(df['pred_prob'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_xgb')['churn'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_xgb')['pred_prob'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_xgb',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"Actutal_event_rate\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"Predicted_event_rate\", data=sorted_reindexed,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"cum_event_cap\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"cum_random_cap\", data=sorted_reindexed,color='blue')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"cum_non_event_cap\", data=sorted_reindexed,color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
